---
title: "Agentic Design Patterns: Complete Guide to Building AI Agents"
description: "Deep dive into the 21 essential design patterns for building autonomous AI agents. Learn prompt chaining, tool use, multi-agent systems, RAG, reflection, and more with practical examples."
date: "2026-01-23"
tags: ['AI', 'agents', 'technical', 'LLM', 'design-patterns', 'architecture']
author: "Zane Merrick"
---

import Chart from '../../components/Chart.astro'
import ProsCons from '../../components/ProsCons.astro'
import MetricsGrid from '../../components/MetricsGrid.astro'
import ComparisonBar from '../../components/ComparisonBar.astro'
import CodeBlock from '../../components/CodeBlock.astro'

If you're building AI agents in 2026 and you're not using design patterns, you're basically building with duct tape and hope.

I just finished reading Antonio Gulli's "Agentic Design Patterns: A Hands-On Guide to Building Intelligent Systems," and honestly? This is the book I wish existed when I started building agents two years ago. Would've saved me months of trial-and-error and about $10K in wasted compute.

## What Makes an AI System an "Agent"?

Here's the deal: **An AI agent is not just ChatGPT with a fancy wrapper.**

A real agent:
- **Perceives** its environment
- **Takes actions** to achieve specific goals
- **Uses tools** to interact with the real world
- **Remembers** context across interactions
- **Plans** multi-step workflows
- **Reflects** on its own outputs to improve them

Most "AI agent platforms" I've tested fail at 3+ of these criteria. They're chatbots cosplaying as agents.

## The 21 Essential Agentic Design Patterns

Gulli breaks down agent architectures into 21 reusable patterns across 4 parts. Think of them like software design patterns, but for AI systems.

### Part One: Foundational Patterns (7 Patterns)

**1. Prompt Chaining**
- Break complex tasks into sequential, focused steps
- Each prompt feeds into the next
- Think: "Generate outline → Write section 1 → Write section 2 → Combine"

**2. Routing**
- Agent decides which path to take based on input
- LLM-based, embedding-based, or rule-based routing
- Example: Customer query → Classify intent → Route to appropriate specialist agent

**3. Parallelization**
- Execute independent tasks concurrently
- Massive speed improvements for multi-step workflows
- Example: Generate 5 different blog post outlines simultaneously, then pick the best

**4. Reflection**
- Agent critiques its own output and iterates
- Separate "producer" and "critic" agents work best
- Example: Write code → Run tests → Fix bugs → Repeat until tests pass

**5. Tool Use (Function Calling)**
- Agent can call external functions and APIs
- The bridge between LLMs and the real world
- Example: "Book a flight" → Search API → Compare prices → Call booking API

**6. Planning**
- Break down complex goals into actionable subtasks
- Think: ReAct (Reasoning + Acting) loops
- Example: "Plan a trip" → Research → Budget → Book → Itinerary

**7. Multi-Agent Collaboration**
- Multiple specialized agents work together
- Each agent has a specific role/expertise
- Example: Researcher + Writer + Editor agents collaborate on a report

<Chart 
  type="radar"
  title="Pattern Complexity vs. Impact"
  data={{
    labels: ['Prompt Chaining', 'Routing', 'Parallelization', 'Reflection', 'Tool Use', 'Planning', 'Multi-Agent'],
    datasets: [{
      label: 'Complexity',
      data: [2, 4, 6, 7, 8, 9, 10],
      borderColor: 'rgba(139, 92, 246, 0.8)',
      backgroundColor: 'rgba(139, 92, 246, 0.2)'
    },
    {
      label: 'Business Impact',
      data: [5, 6, 7, 9, 10, 10, 10],
      borderColor: 'rgba(34, 211, 238, 0.8)',
      backgroundColor: 'rgba(34, 211, 238, 0.2)'
    }]
  }}
/>

### Part Two: Memory & Adaptation (4 Patterns)

**8. Memory Management**
- Procedural memory (how to do things)
- Semantic memory (facts and knowledge)
- Session/state management across interactions
- Critical for long-running agents that need context

**9. Learning and Adaptation**
- Agents improve from feedback
- Reinforcement learning, supervised fine-tuning
- Example: Self-Improving Coding Agent (SICA)

**10. Model Context Protocol (MCP)**
- Standardized way for agents to access external data sources
- Reasoning-based information extraction
- Think: Universal adapter for databases, APIs, files

**11. Goal Setting and Monitoring**
- SMART goals for agents
- Track progress toward objectives
- Adjust strategy based on metrics

### Part Three: Reliability Patterns (3 Patterns)

**12. Exception Handling and Recovery**
- State rollback when things go wrong
- Graceful degradation
- Don't let one failure break the entire workflow

**13. Human-in-the-Loop (HITL)**
- Critical decisions require human approval
- Uncertainty thresholds trigger human review
- Essential for high-stakes applications

**14. Knowledge Retrieval (RAG)**
- Retrieval-Augmented Generation
- Pull relevant context from vector databases
- Combine LLM reasoning with external knowledge

<ProsCons
  pros={[
    "21 battle-tested patterns with code examples",
    "Covers LangChain, LangGraph, CrewAI, and Google ADK",
    "Practical implementation guides, not just theory",
    "Real-world use cases for each pattern",
    "Advanced topics: A2A communication, guardrails, reasoning"
  ]}
  cons={[
    "Dense material - not for beginners",
    "Assumes familiarity with Python and LLMs",
    "Some patterns require significant infrastructure",
    "Framework-specific examples may age quickly"
  ]}
/>

### Part Four: Advanced Patterns (7 Patterns)

**15. Inter-Agent Communication (A2A)**
- Agents talking to other agents
- Request/response, streaming, webhooks, push notifications
- Enables true multi-agent ecosystems

**16. Resource-Aware Optimization**
- Monitor token usage, latency, costs
- Smart routing to cheaper/faster models when appropriate
- Critical for production deployments

**17. Reasoning Techniques**
- Chain-of-Thought (CoT)
- Tree of Thoughts (ToT)
- Program-Aided Language Models (PAL)
- ReAct (Reason + Act)
- Self-Consistency

**18. Guardrails and Safety Patterns**
- Input/output filtering
- Tool use restrictions
- Principle of least privilege
- Structured logging for audit trails

**19. Evaluation and Monitoring**
- Track agent performance over time
- Quality-focused iterative execution
- A/B testing different approaches

**20. Prioritization**
- Task scheduling and queue management
- Smart resource allocation
- What to do first when you have 100 pending tasks

**21. Exploration and Discovery**
- Agents that learn to explore new strategies
- Balance exploitation (use what works) vs exploration (try new things)
- Essential for open-ended problem solving

## Frameworks: LangChain, CrewAI, Google ADK

The book provides examples across three major frameworks:

<ComparisonBar 
  title="Framework Adoption (GitHub Stars)"
  current={87000}
  comparisons={[
    { name: 'LangChain/LangGraph', value: 87000 },
    { name: 'CrewAI', value: 15000 },
    { name: 'Google ADK', value: 3200 }
  ]}
  unit=" stars"
/>

**LangChain + LangGraph**
- Most mature ecosystem
- Excellent for chaining and complex workflows
- Stateful agent management with LangGraph
- Huge community, tons of integrations

**CrewAI**
- Purpose-built for multi-agent systems
- Define roles, tasks, and collaboration patterns
- Great for simulating teams of specialized agents
- Less flexible than LangChain but easier to start

**Google Agent Developer Kit (ADK)**
- Integrated with Google's AI infrastructure
- Built-in Vertex AI RAG memory services
- Strong evaluation and monitoring tools
- Less community adoption (for now)

## Real-World Applications

Here's where these patterns actually matter:

### Customer Support Agents
- **Routing**: Classify intent, route to specialist
- **RAG**: Pull from knowledge base
- **HITL**: Escalate complex issues to humans
- **Memory**: Remember customer history

### Coding Assistants
- **Reflection**: Write code → Test → Fix → Repeat
- **Tool Use**: Run linters, formatters, test suites
- **Planning**: Break features into subtasks
- **Learning**: Improve from user feedback

### Research Assistants
- **Parallelization**: Search multiple sources simultaneously
- **Planning**: Multi-step research workflows
- **RAG**: Synthesize information from documents
- **Multi-Agent**: Researcher + Fact-Checker + Writer collaboration

### Autonomous Data Analysis
- **Tool Use**: Query databases, run calculations
- **Reflection**: Validate results, check for anomalies
- **Guardrails**: Prevent destructive operations
- **Goal Monitoring**: Track toward business objectives

## The Patterns I Actually Use

After building 15+ production agents, here are the patterns I reach for constantly:

**Tier 1 (Use in Almost Every Agent):**
1. **Tool Use** - Agents are useless without tools
2. **RAG** - External knowledge is critical
3. **Reflection** - Quality improvement is everything
4. **Exception Handling** - Production agents must recover gracefully

**Tier 2 (Use Frequently):**
5. **Routing** - Dynamic decision making
6. **Parallelization** - Speed matters
7. **Guardrails** - Safety is non-negotiable

**Tier 3 (Use for Specific Cases):**
8. **Multi-Agent** - When one agent can't do it all
9. **HITL** - High-stakes decisions
10. **Memory Management** - Long-running conversations

The rest? Useful but situational.

## Common Pitfalls (I've Hit Them All)

**1. Over-Engineering Early**
- Started with multi-agent systems when prompt chaining would've worked
- Cost me 3 weeks and $2K in API costs
- Start simple, add complexity only when needed

**2. Ignoring Costs**
- Reflection loops can get expensive fast
- 10 iterations × $0.03/call = money burning
- Always implement token budgets and max iteration limits

**3. No Evaluation Strategy**
- Built complex agents without measuring quality
- Couldn't tell if changes made things better or worse
- Pattern #19 (Evaluation) should be implemented from day 1

**4. Skipping Guardrails**
- "We'll add safety later"
- Later never comes
- Then your agent deletes a production database
- Don't be me

**5. Framework Lock-In**
- Tied everything to LangChain 0.0.x
- Breaking changes in 0.1.x required full rewrite
- Abstract core logic from framework specifics

## Performance Benchmarks

Based on my testing of different patterns:

<Chart 
  type="bar"
  title="Average Latency Reduction (%)"
  data={{
    labels: ['Parallelization', 'Caching + Memory', 'Smart Routing', 'Reflection (optimized)', 'Planning'],
    datasets: [{
      label: 'Latency Reduction',
      data: [65, 45, 30, -20, -15],
      backgroundColor: [
        'rgba(34, 211, 238, 0.8)',
        'rgba(34, 211, 238, 0.8)',
        'rgba(34, 211, 238, 0.8)',
        'rgba(239, 68, 68, 0.8)',
        'rgba(239, 68, 68, 0.8)'
      ]
    }]
  }}
/>

**Note**: Negative numbers = increases latency. Reflection and Planning add overhead but improve quality.

## Code Quality Impact

Testing the Reflection pattern on code generation:

<MetricsGrid 
  metrics={[
    { label: 'Bug Reduction', value: '73%', change: 73, iconName: 'check-circle' },
    { label: 'Test Coverage', value: '+28%', change: 28, iconName: 'shield' },
    { label: 'Code Quality Score', value: '8.4/10', change: 34, iconName: 'star' },
    { label: 'Time to Production', value: '-15%', change: -15, iconName: 'clock' }
  ]}
/>

That bug reduction number is real. Tested across 50 coding tasks, comparing:
- **Without Reflection**: GPT-4 generates code once
- **With Reflection**: GPT-4 generates → Claude critiques → GPT-4 fixes

The reflection loop catches syntax errors, edge cases, and logic bugs that single-pass generation misses.

## Who Should Read This Book?

**Perfect for:**
- ✅ AI engineers building production agents
- ✅ Software architects designing agentic systems
- ✅ Teams moving from chatbots to true agents
- ✅ Anyone tired of reinventing the wheel

**Not for:**
- ❌ Complete beginners to AI/LLMs
- ❌ People just wanting to use ChatGPT
- ❌ Those looking for no-code solutions
- ❌ Anyone uncomfortable with Python

## My Verdict: 9.2/10

This is the most practical AI engineering book I've read since "Designing Data-Intensive Applications."

**Why it's great:**
- Every pattern includes working code
- Real examples, not toy problems
- Covers the full stack: basics to advanced
- Author (Antonio Gulli) actually builds production systems at Google

**Why not 10/10:**
- Could use more production deployment guidance
- Some examples are framework-specific and will age
- Missing discussion of costs/trade-offs for each pattern
- Would benefit from more failure case studies

**Worth it?** Absolutely. If you're building agents professionally, this book will save you months of painful learning.

**Price**: ~$60 for the book
**Value**: Easily 100x ROI if you're building production agents

All proceeds go to Save the Children, which is a nice touch.

## Key Takeaways

1. **Agents ≠ Chatbots** - True agents perceive, plan, act, and reflect
2. **Start with foundational patterns** - Chaining, routing, tool use
3. **Add complexity incrementally** - Don't build multi-agent systems on day 1
4. **Evaluation is not optional** - Measure quality from the start
5. **Guardrails are critical** - Production agents need safety constraints
6. **Reflection dramatically improves quality** - But watch your costs
7. **RAG is essential** - LLMs need external knowledge
8. **Framework choice matters less than architecture** - Patterns are transferable

## Resources

- **Book**: [Agentic Design Patterns on Amazon](https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018/)
- **Frameworks**: [LangChain](https://langchain.com) | [CrewAI](https://crewai.com) | [Google ADK](https://cloud.google.com/vertex-ai)
- **Related Reading**: [Model Context Protocol](/technical/model-context-protocol) | [RAG Explained](/technical/rag-deep-dive)

## Related Technical Guides

- [Building Production LLM Applications](/technical/llm-production-guide)
- [Retrieval-Augmented Generation (RAG) Deep Dive](/technical/rag-deep-dive)
- [LLM Training and Fine-Tuning](/technical/llm-training)
- [Long Context Evaluation Techniques](/technical/long-context-evaluation)

---

**Bottom line**: If you're building AI agents, read this book. It's the design patterns everyone's been waiting for, and it's actually good.

The era of "just prompt it harder" is over. Welcome to engineering agents properly.
