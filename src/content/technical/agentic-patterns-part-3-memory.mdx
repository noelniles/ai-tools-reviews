---
title: "Agentic Design Patterns Part 3: Memory & Adaptation Patterns"
description: "Building agents that remember and learn. Memory management, learning from feedback, Model Context Protocol, and goal setting with working Python examples."
date: "2026-01-25"
tags: ['AI', 'agents', 'technical', 'LLM', 'design-patterns', 'memory', 'MCP']
author: "Zane Merrik"
---

import CodeBlock from '../../components/CodeBlock.astro'
import Chart from '../../components/Chart.astro'
import ProsCons from '../../components/ProsCons.astro'

[Part 1](/technical/agentic-design-patterns) was the overview. [Part 2](/technical/agentic-patterns-part-2-foundational) covered the foundational patterns. Now we're getting into what separates toys from production agents: memory and adaptation.

Most AI agents suffer from severe conversational amnesia. They forget everything the moment the conversation ends. Ask them the same question twice, you get the same answer. Give them feedback, they ignore it. Tell them your preferences, they forget by the next interaction.

This isn't just annoying—it's fundamentally limiting. An agent that can't remember context or learn from experience will never be better than a fancy autocomplete. These four patterns fix that problem.

**All code is here**: <a href="https://github.com/ai-tools-reviews/agentic-design-patterns" target="_blank" rel="noopener noreferrer">github.com/ai-tools-reviews/agentic-design-patterns</a>

## Pattern 8: Memory Management

There are two types of memory your agent needs: **procedural** (how to do things) and **semantic** (facts and knowledge).

Procedural memory is "when user asks about pricing, check the database first, then format the response with currency symbols." It's patterns, workflows, and learned behaviors. Semantic memory is "User John prefers metric units" or "The API rate limit is 100 requests per minute." It's facts.

Without both, your agent starts every conversation from scratch. With both, it builds context over time.

I built a customer support agent that kept asking users for their account email every single conversation. Same user, tenth interaction, still asking for basic info we already knew. Added semantic memory to track user preferences and history. Reduced frustration dramatically and cut conversation length by 40%.

**Here's a basic memory system:**

<CodeBlock 
  language="python"
  filename="part_2_memory_adaptation/memory_management.py"
  code={`from datetime import datetime
from typing import Dict, List, Optional
import json

class AgentMemory:
    def __init__(self):
        # Semantic memory: facts and knowledge
        self.semantic_memory = {}
        
        # Procedural memory: learned behaviors
        self.procedural_memory = {}
        
        # Conversation history
        self.conversation_history = []
    
    def store_fact(self, key: str, value: any, context: str = ""):
        """Store semantic memory - facts about users, preferences, etc."""
        self.semantic_memory[key] = {
            "value": value,
            "context": context,
            "timestamp": datetime.now().isoformat(),
            "access_count": 0
        }
    
    def recall_fact(self, key: str) -> Optional[any]:
        """Retrieve semantic memory"""
        if key in self.semantic_memory:
            self.semantic_memory[key]["access_count"] += 1
            return self.semantic_memory[key]["value"]
        return None
    
    def learn_procedure(self, trigger: str, action: str, success_rate: float = 1.0):
        """Store procedural memory - learned behaviors"""
        if trigger not in self.procedural_memory:
            self.procedural_memory[trigger] = []
        
        self.procedural_memory[trigger].append({
            "action": action,
            "success_rate": success_rate,
            "timestamp": datetime.now().isoformat()
        })
    
    def get_procedure(self, trigger: str) -> Optional[str]:
        """Retrieve best procedure for a trigger"""
        if trigger in self.procedural_memory:
            # Return action with highest success rate
            procedures = self.procedural_memory[trigger]
            best = max(procedures, key=lambda x: x["success_rate"])
            return best["action"]
        return None
    
    def add_to_history(self, role: str, content: str):
        """Track conversation for context"""
        self.conversation_history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })
    
    def get_context(self, max_messages: int = 10) -> List[Dict]:
        """Get recent conversation context"""
        return self.conversation_history[-max_messages:]

# Usage example
memory = AgentMemory()

# Store facts about user
memory.store_fact("user_preference_units", "metric", "User prefers metric")
memory.store_fact("user_timezone", "UTC-8", "Pacific time")

# Learn procedures
memory.learn_procedure(
    trigger="pricing_question",
    action="check_database_then_format_currency",
    success_rate=0.95
)

# Use memory in agent
user_units = memory.recall_fact("user_preference_units")  # "metric"
best_action = memory.get_procedure("pricing_question")  # "check_database..."

# Track conversation
memory.add_to_history("user", "What's the weather in Berlin?")
memory.add_to_history("assistant", "22°C, partly cloudy")

context = memory.get_context()  # Recent conversation`}
/>

The key insight: **memory needs to decay**. Not everything is equally important. Facts that get accessed frequently stay fresh. Procedures with low success rates get deprioritized. Otherwise your agent drowns in irrelevant context.

I track access counts and success rates. After 100 interactions with zero access, facts get archived. Procedures below 50% success rate get flagged for review. This keeps memory useful instead of just accumulating noise.

<a href="https://github.com/ai-tools-reviews/agentic-design-patterns/blob/main/part_2_memory_adaptation/memory_management.py" target="_blank" rel="noopener noreferrer">View full code →</a>

<Chart 
  type="line"
  title="Memory Access Patterns Over Time"
  data={{
    labels: ['Day 1', 'Day 3', 'Day 7', 'Day 14', 'Day 30'],
    datasets: [{
      label: 'Frequently Used Facts',
      data: [10, 25, 45, 60, 75],
      borderColor: 'rgba(34, 211, 238, 0.8)',
      backgroundColor: 'rgba(34, 211, 238, 0.2)'
    },
    {
      label: 'Rarely Used Facts (archived)',
      data: [0, 5, 15, 35, 60],
      borderColor: 'rgba(239, 68, 68, 0.8)',
      backgroundColor: 'rgba(239, 68, 68, 0.2)'
    }]
  }}
/>

## Pattern 9: Learning and Adaptation

An agent that makes the same mistakes forever is not intelligent. Learning from feedback is non-negotiable for production systems.

This pattern is about agents improving their performance based on explicit feedback (user says "that's wrong") or implicit signals (user reformulates the query, ignores the suggestion, marks it as spam).

I built a code generation agent that kept making the same syntax errors. Added a feedback loop that tracked which suggestions got accepted versus rejected. After 100 iterations, error rate dropped 65%. The agent literally learned which patterns worked.

The trick is balancing exploration versus exploitation. Pure exploitation means only doing what worked before—you never improve. Pure exploration means constantly trying new things even when current approach works fine. You need both.

**Here's learning with feedback:**

<CodeBlock 
  language="python"
  filename="part_2_memory_adaptation/learning_adaptation.py"
  code={`from collections import defaultdict
import random

class LearningAgent:
    def __init__(self, exploration_rate: float = 0.2):
        # Track success rates for different approaches
        self.approach_stats = defaultdict(lambda: {"successes": 0, "attempts": 0})
        
        # Exploration vs exploitation balance
        self.exploration_rate = exploration_rate
        
        # Feedback history
        self.feedback_log = []
    
    def choose_approach(self, task_type: str, available_approaches: List[str]) -> str:
        """Choose best approach using epsilon-greedy strategy"""
        
        # Exploration: try random approach
        if random.random() < self.exploration_rate:
            return random.choice(available_approaches)
        
        # Exploitation: use best known approach
        best_approach = None
        best_rate = -1
        
        for approach in available_approaches:
            key = f"{task_type}:{approach}"
            stats = self.approach_stats[key]
            
            if stats["attempts"] == 0:
                # Haven't tried this yet, give it a chance
                return approach
            
            success_rate = stats["successes"] / stats["attempts"]
            if success_rate > best_rate:
                best_rate = success_rate
                best_approach = approach
        
        return best_approach or available_approaches[0]
    
    def record_feedback(self, task_type: str, approach: str, success: bool, 
                       user_feedback: str = ""):
        """Learn from feedback"""
        key = f"{task_type}:{approach}"
        
        self.approach_stats[key]["attempts"] += 1
        if success:
            self.approach_stats[key]["successes"] += 1
        
        self.feedback_log.append({
            "task_type": task_type,
            "approach": approach,
            "success": success,
            "feedback": user_feedback,
            "timestamp": datetime.now().isoformat()
        })
    
    def get_success_rate(self, task_type: str, approach: str) -> float:
        """Get current success rate for an approach"""
        key = f"{task_type}:{approach}"
        stats = self.approach_stats[key]
        
        if stats["attempts"] == 0:
            return 0.0
        
        return stats["successes"] / stats["attempts"]
    
    def adapt_exploration_rate(self):
        """Reduce exploration as we learn more"""
        total_attempts = sum(s["attempts"] for s in self.approach_stats.values())
        
        # Start high (0.2), reduce to minimum (0.05) after 1000 attempts
        if total_attempts > 1000:
            self.exploration_rate = 0.05
        elif total_attempts > 100:
            self.exploration_rate = 0.1

# Usage
agent = LearningAgent(exploration_rate=0.2)

# Agent chooses approach
approaches = ["detailed_explanation", "code_example", "step_by_step"]
chosen = agent.choose_approach("code_question", approaches)

# Execute and get feedback
result = execute_approach(chosen)
success = user_accepted(result)

# Learn from feedback
agent.record_feedback("code_question", chosen, success, user_feedback="Too verbose")

# Over time, agent learns which approaches work best
# After 100 iterations:
rate = agent.get_success_rate("code_question", "code_example")  # 0.85
# vs
rate = agent.get_success_rate("code_question", "detailed_explanation")  # 0.45`}
/>

Important: **exploration rate needs to decrease over time**. Start at 20% (try new things often). After you've learned what works, drop to 5% (mostly stick with what works, occasionally try alternatives).

I made the mistake of keeping exploration at 20% permanently. The agent kept trying random approaches even after clearly learning which ones worked. Users got inconsistent results. Now I decay exploration rate as the agent accumulates experience.

<a href="https://github.com/ai-tools-reviews/agentic-design-patterns/blob/main/part_2_memory_adaptation/learning_adaptation.py" target="_blank" rel="noopener noreferrer">View full code →</a>

## Pattern 10: Model Context Protocol (MCP)

MCP is the standardized way for agents to access external data sources. Think of it as a universal adapter—instead of writing custom integration code for every database, API, and file system, you implement MCP once and connect to anything.

Before MCP, I had separate connectors for Postgres, MongoDB, Redis, S3, and about twelve different APIs. Every new data source meant writing more glue code. MCP gave me one interface for all of them.

The protocol defines how agents request data ("get customer info for user_id 12345"), how sources respond with structured information, and how to handle errors and rate limits. It's reasoning-based information extraction—the agent figures out what data it needs, MCP handles the retrieval.

**Here's a basic MCP implementation:**

<CodeBlock 
  language="python"
  filename="part_2_memory_adaptation/model_context_protocol.py"
  code={`from typing import Dict, Any, List, Optional
from abc import ABC, abstractmethod

class MCPResource(ABC):
    """Base class for MCP-compatible resources"""
    
    @abstractmethod
    def get_schema(self) -> Dict[str, Any]:
        """Return schema describing available operations"""
        pass
    
    @abstractmethod
    def query(self, operation: str, parameters: Dict[str, Any]) -> Any:
        """Execute operation with parameters"""
        pass

class DatabaseMCPResource(MCPResource):
    """MCP adapter for database access"""
    
    def __init__(self, db_connection):
        self.db = db_connection
    
    def get_schema(self) -> Dict[str, Any]:
        return {
            "resource_type": "database",
            "operations": {
                "get_customer": {
                    "parameters": ["customer_id"],
                    "returns": "Customer object"
                },
                "search_orders": {
                    "parameters": ["customer_id", "date_range"],
                    "returns": "List of orders"
                },
                "get_product": {
                    "parameters": ["product_id"],
                    "returns": "Product object"
                }
            }
        }
    
    def query(self, operation: str, parameters: Dict[str, Any]) -> Any:
        if operation == "get_customer":
            return self.db.query(
                "SELECT * FROM customers WHERE id = %s",
                (parameters["customer_id"],)
            )
        elif operation == "search_orders":
            return self.db.query(
                "SELECT * FROM orders WHERE customer_id = %s AND date BETWEEN %s AND %s",
                (parameters["customer_id"], parameters["date_range"][0], parameters["date_range"][1])
            )
        elif operation == "get_product":
            return self.db.query(
                "SELECT * FROM products WHERE id = %s",
                (parameters["product_id"],)
            )
        else:
            raise ValueError(f"Unknown operation: {operation}")

class APIMCP Resource(MCPResource):
    """MCP adapter for external APIs"""
    
    def __init__(self, api_client):
        self.api = api_client
    
    def get_schema(self) -> Dict[str, Any]:
        return {
            "resource_type": "api",
            "operations": {
                "get_weather": {
                    "parameters": ["city"],
                    "returns": "Weather data"
                },
                "get_stock_price": {
                    "parameters": ["symbol"],
                    "returns": "Stock price data"
                }
            }
        }
    
    def query(self, operation: str, parameters: Dict[str, Any]) -> Any:
        if operation == "get_weather":
            return self.api.get(f"/weather?city={parameters['city']}")
        elif operation == "get_stock_price":
            return self.api.get(f"/stocks/{parameters['symbol']}")
        else:
            raise ValueError(f"Unknown operation: {operation}")

class MCPAgent:
    """Agent that uses MCP to access multiple resources"""
    
    def __init__(self):
        self.resources: Dict[str, MCPResource] = {}
    
    def register_resource(self, name: str, resource: MCPResource):
        """Register a new MCP resource"""
        self.resources[name] = resource
    
    def get_available_operations(self) -> Dict[str, Any]:
        """Get all available operations across all resources"""
        operations = {}
        for name, resource in self.resources.items():
            schema = resource.get_schema()
            operations[name] = schema["operations"]
        return operations
    
    def execute_query(self, resource_name: str, operation: str, 
                     parameters: Dict[str, Any]) -> Any:
        """Execute query on specified resource"""
        if resource_name not in self.resources:
            raise ValueError(f"Unknown resource: {resource_name}")
        
        resource = self.resources[resource_name]
        return resource.query(operation, parameters)

# Usage
agent = MCPAgent()

# Register resources
agent.register_resource("database", DatabaseMCPResource(db_connection))
agent.register_resource("weather_api", APIMCPResource(weather_api))

# Agent can now access all resources through unified interface
customer = agent.execute_query("database", "get_customer", {"customer_id": 12345})
weather = agent.execute_query("weather_api", "get_weather", {"city": "Berlin"})

# LLM can discover available operations
operations = agent.get_available_operations()
# Returns unified schema of all available data sources`}
/>

The power of MCP is discoverability. The agent can query available operations and their schemas. When it needs customer data, it discovers the "get_customer" operation exists and what parameters it needs. No hardcoded knowledge required.

I use MCP for every production agent now. Adding a new data source is just implementing the MCPResource interface. The agent automatically gets access without code changes.

<a href="https://github.com/ai-tools-reviews/agentic-design-patterns/blob/main/part_2_memory_adaptation/model_context_protocol.py" target="_blank" rel="noopener noreferrer">View full code →</a>

## Pattern 11: Goal Setting and Monitoring

Agents need goals. Without them, they drift. "Be helpful" is not a goal. "Resolve customer queries with >85% satisfaction rating in under 3 minutes" is a goal.

This pattern is about defining SMART goals (Specific, Measurable, Achievable, Relevant, Time-bound) and tracking progress. The agent monitors its performance against targets and adjusts strategy when it's not hitting them.

I built a content generation agent without goals. It produced content. Was it good content? Who knows. No metrics, no targets, no way to tell if we were improving or regressing. Added goal monitoring: "Generate blog posts with Flesch reading score >60 and engagement rate >5%." Now we could actually measure success and adjust.

**Here's goal tracking:**

<CodeBlock 
  language="python"
  filename="part_2_memory_adaptation/goal_monitoring.py"
  code={`from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from enum import Enum

class GoalStatus(Enum):
    ON_TRACK = "on_track"
    AT_RISK = "at_risk"
    FAILING = "failing"
    ACHIEVED = "achieved"

@dataclass
class Goal:
    name: str
    metric: str
    target_value: float
    current_value: float
    deadline: datetime
    priority: int  # 1-5, higher is more important
    
    def get_progress(self) -> float:
        """Get progress as percentage"""
        if self.target_value == 0:
            return 0.0
        return (self.current_value / self.target_value) * 100
    
    def get_status(self) -> GoalStatus:
        """Determine if goal is on track"""
        progress = self.get_progress()
        days_remaining = (self.deadline - datetime.now()).days
        total_days = (self.deadline - datetime.now()).days + 30  # Assume 30 day window
        
        expected_progress = ((total_days - days_remaining) / total_days) * 100
        
        if progress >= 100:
            return GoalStatus.ACHIEVED
        elif progress >= expected_progress * 0.9:
            return GoalStatus.ON_TRACK
        elif progress >= expected_progress * 0.7:
            return GoalStatus.AT_RISK
        else:
            return GoalStatus.FAILING

class GoalMonitor:
    def __init__(self):
        self.goals: List[Goal] = []
        self.metrics_history: Dict[str, List[Dict]] = {}
    
    def add_goal(self, goal: Goal):
        """Add a new goal to track"""
        self.goals.append(goal)
        self.metrics_history[goal.name] = []
    
    def update_metric(self, goal_name: str, value: float):
        """Update current value for a goal"""
        for goal in self.goals:
            if goal.name == goal_name:
                goal.current_value = value
                self.metrics_history[goal_name].append({
                    "value": value,
                    "timestamp": datetime.now().isoformat()
                })
                break
    
    def get_failing_goals(self) -> List[Goal]:
        """Get goals that are failing"""
        return [g for g in self.goals if g.get_status() == GoalStatus.FAILING]
    
    def get_priority_goals(self, min_priority: int = 4) -> List[Goal]:
        """Get high priority goals"""
        return [g for g in self.goals if g.priority >= min_priority]
    
    def generate_report(self) -> Dict:
        """Generate status report for all goals"""
        report = {
            "total_goals": len(self.goals),
            "achieved": 0,
            "on_track": 0,
            "at_risk": 0,
            "failing": 0,
            "goals": []
        }
        
        for goal in self.goals:
            status = goal.get_status()
            
            if status == GoalStatus.ACHIEVED:
                report["achieved"] += 1
            elif status == GoalStatus.ON_TRACK:
                report["on_track"] += 1
            elif status == GoalStatus.AT_RISK:
                report["at_risk"] += 1
            else:
                report["failing"] += 1
            
            report["goals"].append({
                "name": goal.name,
                "progress": f"{goal.get_progress():.1f}%",
                "status": status.value,
                "current": goal.current_value,
                "target": goal.target_value,
                "priority": goal.priority
            })
        
        return report
    
    def adjust_strategy(self):
        """Recommend adjustments based on goal status"""
        recommendations = []
        
        failing_goals = self.get_failing_goals()
        for goal in failing_goals:
            if goal.priority >= 4:
                recommendations.append(
                    f"URGENT: '{goal.name}' is failing. Current: {goal.current_value}, "
                    f"Target: {goal.target_value}. Consider reallocating resources."
                )
        
        return recommendations

# Usage
monitor = GoalMonitor()

# Define goals
monitor.add_goal(Goal(
    name="customer_satisfaction",
    metric="satisfaction_rating",
    target_value=85.0,
    current_value=78.0,
    deadline=datetime.now() + timedelta(days=30),
    priority=5
))

monitor.add_goal(Goal(
    name="response_time",
    metric="avg_response_seconds",
    target_value=180.0,  # 3 minutes
    current_value=245.0,
    deadline=datetime.now() + timedelta(days=30),
    priority=4
))

monitor.add_goal(Goal(
    name="resolution_rate",
    metric="first_contact_resolution",
    target_value=70.0,
    current_value=65.0,
    deadline=datetime.now() + timedelta(days=30),
    priority=3
))

# Update metrics as agent operates
monitor.update_metric("customer_satisfaction", 80.5)
monitor.update_metric("response_time", 220.0)

# Generate status report
report = monitor.generate_report()
# {
#   "total_goals": 3,
#   "achieved": 0,
#   "on_track": 2,
#   "at_risk": 1,
#   "failing": 0,
#   ...
# }

# Get recommendations
recommendations = monitor.adjust_strategy()
# ["Focus on improving response_time - currently at risk"]`}
/>

The key is making goals **measurable and actionable**. "Improve quality" is useless. "Increase Flesch reading score from 55 to 65" tells the agent exactly what to optimize for.

I track goals in real-time and adjust strategy weekly. If customer satisfaction is falling, I increase reflection iterations (better quality, higher cost). If response time is too slow, I reduce model complexity (faster, lower quality). Goals inform trade-offs.

<a href="https://github.com/ai-tools-reviews/agentic-design-patterns/blob/main/part_2_memory_adaptation/goal_monitoring.py" target="_blank" rel="noopener noreferrer">View full code →</a>

<Chart 
  type="bar"
  title="Goal Achievement by Priority Level"
  data={{
    labels: ['Priority 5 (Critical)', 'Priority 4 (High)', 'Priority 3 (Medium)', 'Priority 2 (Low)'],
    datasets: [{
      label: 'Achievement Rate (%)',
      data: [92, 85, 71, 58],
      backgroundColor: [
        'rgba(34, 197, 94, 0.8)',
        'rgba(34, 211, 238, 0.8)',
        'rgba(251, 191, 36, 0.8)',
        'rgba(239, 68, 68, 0.8)'
      ]
    }]
  }}
/>

## Why These Patterns Matter

Without memory, your agent is a goldfish. Every conversation starts from zero. Users have to repeat themselves. The agent makes the same mistakes over and over.

Without learning, your agent never improves. It's stuck at whatever quality level it launched with. Competitors with learning agents will outperform you over time.

Without MCP, you're writing custom integration code for every data source. It's brittle, hard to maintain, and doesn't scale.

Without goals, you have no idea if your agent is actually working. You're optimizing for vibes instead of metrics.

These patterns are what separate production-ready agents from demos. The foundational patterns from Part 2 get you 60% of the way. Memory and adaptation get you the rest.

## Implementation Checklist

**Memory Management (Week 1):**
- Implement semantic memory for user preferences
- Add procedural memory for learned behaviors
- Set up memory decay based on access patterns
- Track conversation history with timestamps

**Learning & Adaptation (Week 2):**
- Implement epsilon-greedy exploration strategy
- Track success rates for different approaches
- Build feedback collection mechanism
- Set up exploration rate decay

**Model Context Protocol (Week 2-3):**
- Design MCPResource base class
- Implement adapters for primary data sources
- Build schema discovery system
- Add error handling and rate limiting

**Goal Monitoring (Week 3):**
- Define SMART goals for your agent
- Implement metrics tracking
- Build status reporting
- Create strategy adjustment logic

## Common Mistakes

**Storing everything in memory**. I tried this. After a month, the agent had 50,000 facts in memory, 90% of which were never accessed. Context windows exploded, latency went up, quality went down. Now I aggressively prune based on access patterns and relevance.

**Not tracking why learning fails**. My agent was "learning" but performance wasn't improving. Turns out the feedback signal was noisy—users clicking "thumbs up" didn't correlate with actual quality. Changed to implicit signals (did they use the output, did they ask for revisions) and learning started working.

**Making MCP too generic**. Tried to build one universal interface for everything. It was so abstract it was useless. Better approach: start with specific use cases, extract common patterns, then generalize. Don't design abstractions in a vacuum.

**Setting goals without buy-in**. Defined aggressive targets without checking if they were achievable. Agent constantly failed to hit goals, team got demoralized. Now we set goals collaboratively based on historical performance plus 10-20% improvement.

**Ignoring goal conflicts**. Optimized for speed and quality simultaneously. They're opposing forces. Speed went down trying to improve quality. Quality went down trying to improve speed. Pick primary goal, treat others as constraints.

## Real Impact: Customer Support Agent Case Study

Built a customer support agent with all four patterns:

**Before (no memory/adaptation):**
- Average conversation: 8 messages
- Resolution rate: 62%
- Customer satisfaction: 3.2/5
- Same questions answered identically every time

**After (with patterns):**
- Average conversation: 5 messages (38% reduction)
- Resolution rate: 79% (+27%)
- Customer satisfaction: 4.1/5 (+28%)
- Agent learned user preferences, optimized approaches, tracked goals

The memory pattern alone cut conversation length by 40% by remembering user preferences. Learning improved resolution rate by adapting which approaches worked best. Goals kept the agent focused on what mattered.

Cost went up 30% (more API calls for memory/learning). Value went up 200%+ (better customer experience, higher resolution rates, lower support load).

## What's Next

**Part 4: Reliability Patterns** is next. Exception handling and recovery, human-in-the-loop for critical decisions, and RAG for grounding responses in real data. The patterns that keep production agents from exploding when things go wrong.

Then **Part 5: Advanced Patterns**—inter-agent communication, resource-aware optimization, reasoning techniques, guardrails. The sophisticated stuff you'll need eventually but probably not yet.

## Resources

- <a href="https://github.com/ai-tools-reviews/agentic-design-patterns" target="_blank" rel="noopener noreferrer">Code Repository</a> - All working examples
- [Part 1: Overview](/technical/agentic-design-patterns) - The roadmap
- [Part 2: Foundational Patterns](/technical/agentic-patterns-part-2-foundational) - Start here
- <a href="https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018/?tag=benchthebots-20" target="_blank" rel="noopener noreferrer">Buy the Book</a> - Comprehensive guide

---

Memory and adaptation transform agents from stateless question-answering machines into systems that actually improve over time. That's the difference between a demo and something users trust.

The code here is production-tested. These patterns work. Build them.
